{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.tasks = [f for f in os.listdir(root_dir) if f.startswith('task_')]\n",
    "        # Load query labels\n",
    "        self.query_labels_df = pd.read_csv('./dataset/test_set/query_labels.csv')\n",
    "        \n",
    "    def load_task(self, task_idx):\n",
    "        task_dir = os.path.join(self.root_dir, f'task_{task_idx}')\n",
    "        \n",
    "        # 加载支持集\n",
    "        support_dir = os.path.join(task_dir, 'support')\n",
    "        support_classes = os.listdir(support_dir)\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        \n",
    "        for idx, class_name in enumerate(support_classes):\n",
    "            class_dir = os.path.join(support_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                support_images.append(image)\n",
    "                support_labels.append(idx)\n",
    "        \n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        \n",
    "        # 加载查询集\n",
    "        query_dir = os.path.join(task_dir, 'query')\n",
    "        query_images = []\n",
    "        query_paths = []\n",
    "        query_labels = []  # 新增：存储查询集的真实标签\n",
    "        \n",
    "        for img_name in os.listdir(query_dir):\n",
    "            img_path = os.path.join(query_dir, img_name)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            query_images.append(image)\n",
    "            query_paths.append(img_path)\n",
    "            \n",
    "            # 从CSV文件中获取真实标签\n",
    "            task_name = f'task_{task_idx}'\n",
    "            label = self.query_labels_df[\n",
    "                (self.query_labels_df['img_name'] == img_name)\n",
    "            ]['label'].values[0]\n",
    "            \n",
    "            # 将标签转换为数值索引\n",
    "            label_idx = support_classes.index(label)\n",
    "            query_labels.append(label_idx)\n",
    "            \n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)  # 新增：转换为tensor\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_paths, support_classes, query_labels\n",
    "\n",
    "\n",
    "# 2. 模型定义\n",
    "class PrototypicalNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(PrototypicalNet, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "    def get_prototypes(self, support_images, support_labels):\n",
    "        features = self.forward(support_images)\n",
    "        unique_labels = torch.unique(support_labels)\n",
    "        prototypes = []\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            mask = support_labels == label\n",
    "            prototype = features[mask].mean(0)\n",
    "            prototypes.append(prototype)\n",
    "            \n",
    "        return torch.stack(prototypes)\n",
    "    \n",
    "    def predict(self, prototypes, query_features):\n",
    "        distances = torch.cdist(query_features, prototypes)\n",
    "        return torch.argmin(distances, dim=1)\n",
    "\n",
    "def train_episode(model, support_images, support_labels, query_images, query_labels, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 获取原型\n",
    "    prototypes = model.get_prototypes(support_images, support_labels)\n",
    "    \n",
    "    # 获取查询集特征\n",
    "    query_features = model(query_images)\n",
    "    \n",
    "    # 计算距离和损失\n",
    "    distances = torch.cdist(query_features, prototypes)\n",
    "    log_probas = -distances\n",
    "    loss = nn.CrossEntropyLoss()(log_probas, query_labels)\n",
    "    \n",
    "    # 计算准确率\n",
    "    predictions = torch.argmin(distances, dim=1)\n",
    "    accuracy = (predictions == query_labels).float().mean().item()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), accuracy\n",
    "\n",
    "def evaluate_task(model, support_images, support_labels, query_images, query_labels=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 获取原型\n",
    "        prototypes = model.get_prototypes(support_images, support_labels)\n",
    "        \n",
    "        # 获取查询集特征\n",
    "        query_features = model(query_images)\n",
    "        \n",
    "        # 预测类别\n",
    "        predictions = model.predict(prototypes, query_features)\n",
    "        \n",
    "        # 如果提供了标签，计算准确率\n",
    "        accuracy = None\n",
    "        if query_labels is not None:\n",
    "            accuracy = (predictions == query_labels).float().mean().item()\n",
    "        \n",
    "    return predictions, accuracy\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))  # 确保类别顺序一致\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 收集所有图片路径和标签\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                self.images.append(os.path.join(class_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "class EpisodeSampler:\n",
    "    def __init__(self, dataset, n_way, n_support, n_query):\n",
    "        self.dataset = dataset\n",
    "        self.n_way = n_way  # 每个episode的类别数\n",
    "        self.n_support = n_support  # 每个类别的支持集样本数\n",
    "        self.n_query = n_query  # 每个类别的查询集样本数\n",
    "        \n",
    "        # 按类别组织数据\n",
    "        self.label_to_indices = {}\n",
    "        for idx, label in enumerate(dataset.labels):\n",
    "            if label not in self.label_to_indices:\n",
    "                self.label_to_indices[label] = []\n",
    "            self.label_to_indices[label].append(idx)\n",
    "    \n",
    "    def sample_episode(self):\n",
    "        # 随机选择n_way个类别\n",
    "        selected_classes = np.random.choice(\n",
    "            list(self.label_to_indices.keys()), \n",
    "            self.n_way, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # 为每个选中的类别采样支持集和查询集\n",
    "        for class_idx, class_label in enumerate(selected_classes):\n",
    "            # 获取这个类别的所有样本索引\n",
    "            class_indices = self.label_to_indices[class_label]\n",
    "            \n",
    "            # 随机选择支持集和查询集的样本\n",
    "            selected_indices = np.random.choice(\n",
    "                class_indices,\n",
    "                self.n_support + self.n_query,\n",
    "                replace=False\n",
    "            )\n",
    "            \n",
    "            # 分割为支持集和查询集\n",
    "            support_idx = selected_indices[:self.n_support]\n",
    "            query_idx = selected_indices[self.n_support:]\n",
    "            \n",
    "            # 收集支持集样本\n",
    "            for idx in support_idx:\n",
    "                image, _ = self.dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(class_idx)\n",
    "            \n",
    "            # 收集查询集样本\n",
    "            for idx in query_idx:\n",
    "                image, _ = self.dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(class_idx)\n",
    "        \n",
    "        # 转换为tensor\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "\n",
    "def main():\n",
    "    # 设置设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 数据转换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 加载训练集\n",
    "    print(\"Loading training dataset...\")\n",
    "    train_dataset = TrainDataset('dataset/train_set', transform=transform)\n",
    "    test_dataset = TestDataset('dataset/test_set', transform=transform)\n",
    "    \n",
    "    # 创建episode采样器\n",
    "    n_way = 10  # 每个episode的类别数\n",
    "    n_support = 5  # 每个类别的支持集样本数\n",
    "    n_query = 2  # 每个类别的查询集样本数\n",
    "    episode_sampler = EpisodeSampler(train_dataset, n_way, n_support, n_query)\n",
    "    \n",
    "    # 初始化模型\n",
    "    print(\"Initializing model...\")\n",
    "    model = PrototypicalNet(pretrained=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 训练循环\n",
    "    num_epochs = 2\n",
    "    episodes_per_epoch = 50  # 每个epoch的episode数量\n",
    "    best_train_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        pbar = tqdm(range(episodes_per_epoch), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for episode in pbar:\n",
    "            # 采样一个episode\n",
    "            support_images, support_labels, query_images, query_labels = episode_sampler.sample_episode()\n",
    "            \n",
    "            # 移动到设备\n",
    "            support_images = support_images.to(device)\n",
    "            support_labels = support_labels.to(device)\n",
    "            query_images = query_images.to(device)\n",
    "            query_labels = query_labels.to(device)\n",
    "            \n",
    "            # 训练一个episode\n",
    "            loss, acc = train_episode(model, support_images, support_labels, \n",
    "                                    query_images, query_labels, optimizer)\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            \n",
    "            # 更新进度条\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss:.4f}',\n",
    "                'acc': f'{acc:.4f}'\n",
    "            })\n",
    "        \n",
    "        # 计算平均训练损失和准确率\n",
    "        avg_train_loss = total_loss / episodes_per_epoch\n",
    "        avg_train_acc = total_acc / episodes_per_epoch\n",
    "        \n",
    "        # 保存最佳训练准确率\n",
    "        best_train_acc = max(best_train_acc, avg_train_acc)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1} Training Stats:')\n",
    "        print(f'Average Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Average Accuracy: {avg_train_acc:.4f}')\n",
    "        print(f'Best Training Accuracy: {best_train_acc:.4f}')\n",
    "        \n",
    "        # 验证阶段\n",
    "        if (epoch + 1) % 1 == 0:  # 每5个epoch进行一次验证\n",
    "            print(\"\\nRunning validation...\")\n",
    "            model.eval()\n",
    "            test_accuracies = []\n",
    "            results = []\n",
    "            \n",
    "            for task_idx in tqdm(range(29), desc=\"Evaluating tasks\"):\n",
    "                support_images, support_labels, query_images, query_paths, support_classes, query_labels = \\\n",
    "                    test_dataset.load_task(task_idx)\n",
    "                \n",
    "                support_images = support_images.to(device)\n",
    "                support_labels = support_labels.to(device)\n",
    "                query_images = query_images.to(device)\n",
    "                query_labels = query_labels.to(device)  # 移动到设备\n",
    "                \n",
    "                # 进行预测\n",
    "                predictions, accuracy = evaluate_task(model, support_images, support_labels, \n",
    "                                                   query_images, query_labels)\n",
    "                \n",
    "                # 记录任务准确率\n",
    "                test_accuracies.append(accuracy)\n",
    "                \n",
    "                # 保存预测结果\n",
    "                for img_path, pred in zip(query_paths, predictions.cpu().numpy()):\n",
    "                    results.append({\n",
    "                        'task': f'task_{task_idx}',\n",
    "                        'image': os.path.basename(img_path),\n",
    "                        'predicted_class': support_classes[pred]\n",
    "                    })\n",
    "            \n",
    "            # 计算并打印平均准确率\n",
    "            avg_test_accuracy = np.mean(test_accuracies)\n",
    "            print(f'\\nAverage Test Accuracy: {avg_test_accuracy:.4f}')\n",
    "            \n",
    "            # 保存最佳测试准确率\n",
    "            if avg_test_accuracy > best_test_acc:\n",
    "                best_test_acc = avg_test_accuracy\n",
    "                print(f'New Best Test Accuracy: {best_test_acc:.4f}')\n",
    "                \n",
    "                # 可选：保存最佳模型\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "            # 保存预测结果\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df.to_csv(f'predictions_epoch_{epoch+1}.csv', index=False)\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
